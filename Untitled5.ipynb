{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import models, transforms\n",
        "from PIL import Image\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "xK864cFKjCgn"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomImageDataset(Dataset):\n",
        "    def __init__(self, csv_file, image_dir, transform=None):\n",
        "        self.data = pd.read_csv(csv_file)\n",
        "        self.image_dir = image_dir\n",
        "        self.transform = transform\n",
        "        self.label_encoder = LabelEncoder()\n",
        "        self.labels = self.label_encoder.fit_transform(self.data['ClassId'])\n",
        "        self.image_ids = self.data['ImageId'].values\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = os.path.join(self.image_dir, f\"{self.image_ids[idx]}.jpg\")\n",
        "        try:\n",
        "            image = Image.open(img_name).convert('RGB')\n",
        "            label = self.labels[idx]\n",
        "            if self.transform:\n",
        "                image = self.transform(image)\n",
        "            return image, label\n",
        "        except FileNotFoundError:\n",
        "            print(f\"Image not found: {img_name}\")\n",
        "            return None"
      ],
      "metadata": {
        "id": "i1FZfnU4jFsX"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.RandomRotation(10),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "}"
      ],
      "metadata": {
        "id": "oBbAqgpUjJxK"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "csv_file = \"/content/drive/MyDrive/Challenge-2/train.csv\"\n",
        "image_dir = \"test_images\"\n",
        "full_dataset = CustomImageDataset(csv_file=csv_file, image_dir=image_dir, transform=None)\n",
        "\n",
        "train_size = int(0.8 * len(full_dataset))\n",
        "val_size = len(full_dataset) - train_size\n",
        "train_dataset, val_dataset = torch.utils.data.random_split(full_dataset, [train_size, val_size])\n",
        "\n",
        "train_dataset.dataset.transform = data_transforms['train']\n",
        "val_dataset.dataset.transform = data_transforms['val']"
      ],
      "metadata": {
        "id": "C8Mb3lGPjN4x"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.resnet50(pretrained=True)\n",
        "num_classes = len(full_dataset.label_encoder.classes_)\n",
        "model.fc = nn.Linear(model.fc.in_features, num_classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8h49jX5ikBXm",
        "outputId": "0b87a4d6-1f68-4250-c6f8-e6d2793470c5"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
            "100%|██████████| 97.8M/97.8M [00:00<00:00, 126MB/s]\n"
          ]
        }
      ]
    }
  ]
}